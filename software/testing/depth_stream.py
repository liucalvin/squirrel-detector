import pyrealsense2 as rs
import numpy as np
import cv2
from flask import Flask, Response

# Initialize Flask app
app = Flask(__name__)

# Configure RealSense pipeline
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)

# Start streaming
pipeline.start(config)

def generate_frames():
    try:
        while True:
            # Wait for a coherent pair of frames: depth
            frames = pipeline.wait_for_frames()
            depth_frame = frames.get_depth_frame()
            if not depth_frame:
                continue

            # Convert depth frame to numpy array
            depth_image = np.asanyarray(depth_frame.get_data())

            # Apply colormap for visualization
            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)

            # Encode the frame to JPEG
            ret, buffer = cv2.imencode('.jpg', depth_colormap)
            frame = buffer.tobytes()

            # Yield the frame in byte format
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')
    finally:
        # Stop streaming
        pipeline.stop()

@app.route('/video_feed')
def video_feed():
    # Return the response generated by the generate_frames function
    return Response(generate_frames(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/')
def index():
    # HTML page to display the video stream
    return """
    <html>
      <head>
        <title>RealSense Depth Stream</title>
      </head>
      <body>
        <h1>RealSense Depth Stream</h1>
        <img src="/video_feed" width="640" height="480">
      </body>
    </html>
    """

if __name__ == '__main__':
    # Run the Flask app
    app.run(host='0.0.0.0', port=5000)
